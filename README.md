# UofC Statistical Learning Study Group
Public repository for the UofC Statistical Learning study group. The group will meet over the summer of 2019 for 11 presentations given by university students and staff on different topics. The objective of the group is to develop foundational knowledge and explore new developments in the fields of statistics and machine learning. 

#### Presenting Members:
- Jordan Bannister
- Deepthi Rajashekar
- Lucas Lo Vercio
- Matthias Wilms
- Anthony Winder
- Anup Tuladhar
- David Katz
- Nagesh Subbanna
- Bryce Besler
- Danielle Whittier


### Meetings
We are planning to meet every second wednesday at noon beginning April 3. Lunch will be provided (hopefully). 

### Course Outline

| Date                     | Topic                                          | Presenter    |
|:------------------------ |:---------------------------------------------- |:---------    |
| Apr. 3<sup>rd</sup>      | Information Theory                             | Jordan       |
| Apr. 17<sup>th</sup>     | Stochastic Processes                           | Deepthi      |
| May. 1<sup>st</sup>      | Decision Trees/Forests                         | Lucas        |
| May. 15<sup>th</sup>     | Computational Anatomy                          | Matthias     |
| May. 29<sup>th</sup>     | Reinforcement Learning                         | Anthony      |
| Jun. 12<sup>th</sup>     | Recurrent Neural Networks                      | Anup/Ahn?    |
| Jun. 26<sup>th</sup>     | Generative Models                              | Anup         |
| Jul. 10<sup>th</sup>     | Bayesian Inference                             | David        |
| Jul. 24<sup>th</sup>     | Probabilistic Graphical Models                 | Nagesh       |
| Aug. 7<sup>th</sup>      | Causal Inference                               | Bryce        |
| Aug. 21<sup>st</sup>     | Multi-level and Mixed Effects Models           | Danielle     |

### Curriculum
The content was selected according to the interests and knowledge of the presenting members. Related topics are (roughly) grouped together.

#### 0 Information Theory 
Information, entropy (conditional, joint, relative, differential), mutual information, coding theory

#### 1 Stochastic Processes
Random walk (levy process), brownian motion, gaussian process, markov process, martingale

#### 2 Decision Trees/Forests 
Decsion trees, bagging (bootstrap aggregation), feature bagging, random forests, information gain

#### 3 Computational Anatomy 
Diffeomorphisms (morphisms, isomorphisms, homeomorphisms, manifolds), diffeomorphism groups, matching/registration (LDMM)

#### 4 Reinforcement Learning 
Markov decision process, policy learning (brute force, monte carlo, Q-learning), exploration vs exploitation (multi-armed bandit problem)

#### 5 Recurrent Neural Networks 
Fully recurrent network, LSTM, training (supervised, reinforcement)

#### 6 Generative Models 
VAE, GAN, deep belief network, style transfer.

#### 7 Bayesian Inference 
Frequentist vs. Bayesian, bayes theorem, maximum likelihood estimates, maximum a posterori estimates, Markov Chain Monte Carlo (MCMC), Variational Inference (VI)

#### 8 Probabilistic Graphical Models
Bayesian networks, markov networks, conditional independence, joint probability factorization, hidden markov models

#### 9 Causal Inference
Association, causation, intervention, counterfactuals, instrumentals, Structural Causal Models (SCM)

#### 10 Multi-level and Mixed Effects Models 
Fixed vs random effects, heirarchical regression
